# -*- coding: utf-8 -*-
"""voicebot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1trnGzqC4-LBUlteADN_KtYFkOk2q_3L8
"""

!pip install streamlit scikit-learn gtts openai-whisper

import streamlit as st
import pandas as pd
import os
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from gtts import gTTS
import whisper
import base64
import tempfile

# Title and Description
st.set_page_config(page_title="üéì Kamaraj College FAQ Chatbot", layout="centered")
st.title("üéì Kamaraj College FAQ Chatbot")
st.write("Ask your question by recording your voice. The bot will transcribe, predict the answer, and speak it back.")

# Load the dataset and train model
@st.cache_resource
def load_model():
    df = pd.read_csv("kcet_qa_bank.csv")
    df.dropna(inplace=True)
    le = LabelEncoder()
    df["Answer_Label"] = le.fit_transform(df["Answer"])
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df["Question"])
    y = df["Answer_Label"]
    model = LogisticRegression()
    model.fit(X, y)
    return model, le, vectorizer, df

model, le, vectorizer, df = load_model()

# Load Whisper model
@st.cache_resource
def load_whisper():
    return whisper.load_model("base")

whisper_model = load_whisper()

# Audio Recorder
st.markdown("### üé§ Record your voice")
audio_file = st.file_uploader("Upload a recorded voice question (WAV/MP3)", type=["wav", "mp3", "m4a"])

if audio_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
        temp_audio.write(audio_file.read())
        temp_audio_path = temp_audio.name

    # Transcribe audio
    with st.spinner("üîç Transcribing your voice..."):
        try:
            result = whisper_model.transcribe(temp_audio_path)
            user_input = result["text"]
            st.success(f"üó£Ô∏è You said: {user_input}")
        except Exception as e:
            st.error(f"Transcription failed: {e}")
            user_input = None

    # Predict and respond
    if user_input:
        try:
            vec = vectorizer.transform([user_input])
            prediction = model.predict(vec)[0]
            answer = le.inverse_transform([prediction])[0]

            # Speak answer using gTTS
            tts = gTTS(text=answer, lang="en")
            answer_path = "answer.mp3"
            tts.save(answer_path)

            st.markdown(f"‚úÖ **Answer:** {answer}")
            audio_bytes = open(answer_path, "rb").read()
            st.audio(audio_bytes, format="audio/mp3")
        except Exception as e:
            st.error(f"Prediction or TTS failed: {e}")
else:
    st.info("‚¨ÜÔ∏è Please upload your recorded voice question.")